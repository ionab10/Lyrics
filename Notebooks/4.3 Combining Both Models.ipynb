{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from time import time\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from scipy.spatial.distance import cosine \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import svm\n",
    "import seaborn as sns\n",
    "\n",
    "le=LabelEncoder()\n",
    "ss=StandardScaler()\n",
    "from gensim import matutils\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.manifold import TSNE\n",
    "tsne=TSNE(metric='cosine')\n",
    "\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Both Models\n",
    "\n",
    "Since the word2vec and feature models represent different aspects of the data, we hope to get a better prediction by combining the two. This new model with include the features used previously, as well as the similarity score to each genre from the word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "model = Doc2Vec.load(\"../Data/doc2vec100.model\")\n",
    "\n",
    "song_df=pd.read_csv(\"../Data/songdata_v2.csv\",sep=',',encoding='utf-8', usecols=['lyrics','genre','song_length','complexity','language'])\n",
    "print(len(song_df))\n",
    "song_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec Genre Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../Data/topics-anthology.txt\",'r') as f:\n",
    "    topics=f.read()\n",
    "    topics=pd.DataFrame([t.split('\\t') for t in topics.split('\\n')], columns=['Genre','words'])\n",
    "    topics['Genre']=[t.title() for t in topics.Genre]\n",
    "    topics.set_index('Genre', inplace=True)\n",
    "\n",
    "topics['vector']=[model.infer_vector(w) for w in topics.words]\n",
    "topics\n",
    "\n",
    "for i,row in song_df.iterrows():\n",
    "    for g in topics.index:\n",
    "        song_df.at[i,'_sim'.format(g)]=1-cosine(model.docvecs[str(i)],topics.loc[g]['vector'])\n",
    "\n",
    "song_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Data/profanity.txt', 'r') as f:\n",
    "    profanity = [x for x in f.read().split('\\n') if x]\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=profanity)\n",
    "count = count_vectorizer.fit_transform(song_df.lyrics.tolist())\n",
    "count = pd.DataFrame(count.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "song_df['profanity']=count.sum(axis=1).div(song_df.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to first person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=['i','me','my', 'myself']\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "count = count_vectorizer.fit_transform(song_df.lyrics.tolist())\n",
    "count = pd.DataFrame(count.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "song_df['1st_ref']=count.sum(axis=1).div(song_df.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to second person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=['you','your', 'yourself']\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "count = count_vectorizer.fit_transform(song_df.lyrics.tolist())\n",
    "count = pd.DataFrame(count.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "song_df['2nd_ref']=count.sum(axis=1).div(song_df.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to third person (male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=['he','him','his', 'man', 'boy']\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "count = count_vectorizer.fit_transform(song_df.lyrics.tolist())\n",
    "count = pd.DataFrame(count.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "song_df['male_ref']=count.sum(axis=1).div(song_df.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference to third person (female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab=['she','her', 'girl', 'lady', 'woman']\n",
    "\n",
    "count_vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "count = count_vectorizer.fit_transform(song_df.lyrics.tolist())\n",
    "count = pd.DataFrame(count.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "song_df['female_ref']=count.sum(axis=1).div(song_df.song_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_df.drop(['lyrics'], axis=1, inplace=True)\n",
    "song_df.fillna('?', inplace=True)\n",
    "\n",
    "song_df['language']=le.fit_transform(song_df['language'])\n",
    "song_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_df=pd.DataFrame()\n",
    "for genre in set(song_df.genre)-{'?'}:\n",
    "    try:\n",
    "        sample_df=sample_df.append(song_df.query(\"genre=='{}'\".format(genre)).sample(1000))\n",
    "    except:\n",
    "        sample_df=sample_df.append(song_df.query(\"genre=='{}'\".format(genre)))\n",
    "\n",
    "train,test=train_test_split(sample_df)\n",
    "print('Train',Counter(train.genre))\n",
    "print('Test',Counter(test.genre))\n",
    "\n",
    "X_train = train.drop('genre', axis=1)\n",
    "y_train = train['genre']\n",
    "\n",
    "X_test = test.drop('genre', axis=1)\n",
    "y_test = test['genre']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc=DecisionTreeClassifier(random_state=0)\n",
    "predicted=dtc.fit(X_train,y_train).predict(X_test) \n",
    "dict(zip(X_train.columns,list(dtc.feature_importances_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conf_mat=confusion_matrix(y_test,predicted,labels=list(set(y_test)))\n",
    "conf_mat=pd.DataFrame(conf_mat, columns=list(set(y_test)))\n",
    "conf_mat['index']=list(set(y_test))\n",
    "conf_mat.set_index('index', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.pcolor(conf_mat, cmap='OrRd')\n",
    "labels=list(set(y_test))\n",
    "plt.yticks(np.arange(0.5, len(labels), 1), labels)\n",
    "plt.xticks(np.arange(0.5, len(labels), 1), labels, rotation=45)\n",
    "plt.title('Proportional Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.colorbar()\n",
    "plt.savefig('../Figures/conf_heatmap_combined.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(dtc,X_train,y_train) #3-fold cross validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
